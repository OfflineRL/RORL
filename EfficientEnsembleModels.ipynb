{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from lifelong_rl.torch import pytorch_util as ptu\n",
    "from lifelong_rl.torch.modules import LayerNorm\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class BatchEnsembleConv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_models, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_models = num_models\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.empty(num_models, in_channels))\n",
    "        self.gamma = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            # use one bias vector per ensemble member\n",
    "            self.bias = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X: Tensor of shape (B * M, C_in, H, W)\n",
    "        Ensemble members should be stacked in BATCH dimension.\n",
    "        Dim 0 layout:\n",
    "            ------ batch elem 0, model 0 ------\n",
    "            -------batch elem 1, model 0 ------\n",
    "                      ...\n",
    "            ------ batch elem 0, model n ------\n",
    "            -------batch elem 1, model n ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        # arguably this is the actual batch size\n",
    "        examples_per_model = batch_size // self.num_models\n",
    "\n",
    "        alpha = self.alpha.tile(1, examples_per_model).view(\n",
    "            batch_size, self.in_channels)[:, :, None, None]\n",
    "        gamma = self.gamma.tile(1, examples_per_model).view(\n",
    "            batch_size, self.out_channels)[:, :, None, None]\n",
    "\n",
    "        x = self.conv(x * alpha) * gamma\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias.tile(1, examples_per_model).view(\n",
    "                batch_size, self.out_channels)[:, :, None, None]\n",
    "            x = x + bias\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.conv.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        # random sign initialization for fast weights as mentioned in paper\n",
    "        with torch.no_grad():\n",
    "            self.alpha.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.gamma.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "\n",
    "\n",
    "class BatchEnsembleConv1D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_models, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_models = num_models\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.empty(num_models, in_channels))\n",
    "        self.gamma = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            # use one bias vector per ensemble member\n",
    "            self.bias = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X: Tensor of shape (B * M, C_in, W)\n",
    "        Ensemble members should be stacked in BATCH dimension.\n",
    "        Dim 0 layout:\n",
    "            ------ batch elem 0, model 0 ------\n",
    "            -------batch elem 1, model 0 ------\n",
    "                      ...\n",
    "            ------ batch elem 0, model n ------\n",
    "            -------batch elem 1, model n ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        # arguably this is the actual batch size\n",
    "        examples_per_model = batch_size // self.num_models\n",
    "\n",
    "        alpha = self.alpha.tile(1, examples_per_model).view(\n",
    "            batch_size, self.in_channels)[:, :, None]\n",
    "        gamma = self.gamma.tile(1, examples_per_model).view(\n",
    "            batch_size, self.out_channels)[:, :, None]\n",
    "\n",
    "        x = self.conv(x * alpha) * gamma\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias.tile(1, examples_per_model).view(\n",
    "                batch_size, self.out_channels)[:, :, None]\n",
    "            x = x + bias\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.conv.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        # random sign initialization for fast weights as mentioned in paper\n",
    "        with torch.no_grad():\n",
    "            self.alpha.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.gamma.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "\n",
    "\n",
    "class BatchEnsembleLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, ensemble_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = input_size\n",
    "        self.out_features = output_size\n",
    "        self.ensemble_size = ensemble_size\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(output_size, input_size))  # m*n\n",
    "        self.r = nn.Parameter(torch.empty(ensemble_size, input_size))  # M*m\n",
    "        self.s = nn.Parameter(torch.empty(ensemble_size, output_size))  # M*n\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(ensemble_size, output_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Expects input in shape (B*M, C_in), dim 0 layout:\n",
    "            ------ x0, model 0 ------\n",
    "            -------x0, model 1 ------\n",
    "                      ...\n",
    "            ------ x1, model 0 ------\n",
    "            -------x1, model 1 ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        B = X.shape[0] // self.ensemble_size\n",
    "        R = self.r.repeat(B, 1)\n",
    "        S = self.s.repeat(B, 1)\n",
    "        bias = self.bias.repeat(B, 1)\n",
    "        # Eq. 5 from BatchEnsembles paper\n",
    "        return torch.mm((X * R), self.W.T) * S + bias  # (B*M, C_out)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
    "\n",
    "        # Another way to initialize the fast weights\n",
    "        #nn.init.normal_(self.r, mean=1., std=0.1)\n",
    "        #nn.init.normal_(self.s, mean=1., std=0.1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.r.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.s.bernoulli_(0.5).mul_(2).add_(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchEnsembleFlattenMLP(\n",
      "  (fc0): BatchEnsembleLinear()\n",
      "  (fc1): BatchEnsembleLinear()\n",
      "  (last_fc): BatchEnsembleLinear()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BatchEnsembleFlattenMLP(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ensemble_size,\n",
    "            hidden_sizes,\n",
    "            input_size,\n",
    "            output_size,\n",
    "            init_w=3e-3,\n",
    "            hidden_init=ptu.fanin_init,\n",
    "            w_scale=1,\n",
    "            b_init_value=0.1,\n",
    "            layer_norm=None,\n",
    "            batch_norm=False,\n",
    "            final_init_scale=None,\n",
    "            norm_input=False,\n",
    "            obs_norm_mean=None,\n",
    "            obs_norm_std=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.sampler = np.random.default_rng()\n",
    "\n",
    "        self.hidden_activation = F.relu\n",
    "        self.output_activation = identity\n",
    "        \n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "\n",
    "        self.fcs = []\n",
    "\n",
    "        if batch_norm:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        in_size = input_size\n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = BatchEnsembleLinear(\n",
    "                ensemble_size=ensemble_size,\n",
    "                input_size=in_size,\n",
    "                output_size=next_size,\n",
    "            )\n",
    "            self.__setattr__('fc%d'% i, fc)\n",
    "            self.fcs.append(fc)\n",
    "            in_size = next_size\n",
    "\n",
    "        self.last_fc = BatchEnsembleLinear(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "        )\n",
    "        if final_init_scale is None:\n",
    "            self.last_fc.W.data.uniform_(-init_w, init_w)\n",
    "            self.last_fc.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        \"\"\"Calculate the forward pass of Q(s, a).\n",
    "\n",
    "        Args:\n",
    "            inputs: list[observation,action]: list of tensors containing the observation and action size B x obs_dim , B x act_dim \n",
    "\n",
    "        Returns:\n",
    "            Q(s,a): return Q(s,a) size B x 1, where emsamble members output are stack along dim 0 [q_m0 , q_m1, ...,q_mN, q_m0, q_m1, ...]^T \n",
    "        \"\"\"\n",
    "        \n",
    "        inputs = [inputs[0], inputs[1]]\n",
    "        if self.norm_input:\n",
    "            inputs[0] = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "\n",
    "        flat_inputs = torch.cat(inputs, dim=-1)\n",
    "        dim=len(flat_inputs.shape)\n",
    "\n",
    "        # input normalization\n",
    "        h = flat_inputs\n",
    "\n",
    "        # standard feedforward network\n",
    "        for _, fc in enumerate(self.fcs):\n",
    "            h = fc(h)\n",
    "            h = self.hidden_activation(h)\n",
    "            if hasattr(self, 'layer_norm') and (self.layer_norm is not None):\n",
    "                h = self.layer_norm(h)\n",
    "        preactivation = self.last_fc(h)\n",
    "        output = self.output_activation(preactivation)\n",
    "\n",
    "        # if original dim was 1D, squeeze the extra created layer\n",
    "        if dim == 1:\n",
    "            output = output.squeeze(1)\n",
    "        return output\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        inputs = [inputs[0].repeat_interleave(self.ensemble_size,0), inputs[1].repeat_interleave(self.ensemble_size,0)]\n",
    "        preds = self.forward(*inputs)\n",
    "        B = preds.shape[0] // self.ensemble_size\n",
    "        #(B*Self.ensemble_size,1) => (self.ensemble_size, B, 1)\n",
    "        preds = preds.view(self.ensemble_size, B, 1)\n",
    "        # Return min, mean and std of the ensemble\n",
    "        return preds.min(0)[0], preds.mean(0), preds.std(0)\n",
    " \n",
    "\n",
    "\n",
    "    def fit_input_stats(self, data, mask=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "A = BatchEnsembleFlattenMLP(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MimoEnsembleFlattenMLP(\n",
      "  (input_layer): Linear(in_features=40, out_features=128, bias=True)\n",
      "  (backbone_model): BackboneModel(\n",
      "    (l0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/noowad93/MIMO-pytorch\n",
    "# (The link above may contain some errors)\n",
    "# https://colab.research.google.com/drive/16i8Wd8hYYgZfVLs6MPVFZ2faccpnYkyk?usp=sharing#scrollTo=i_2GT74Ecu0c\n",
    "# https://colab.research.google.com/drive/1JIgyVeEmlOH-j0oGmeDLV8iE5UYdreYm#scrollTo=Ac1oS_S8kQOB\n",
    "\n",
    "class MimoEnsembleFlattenMLP(nn.Module):\n",
    "    def __init__(self, \n",
    "                ensemble_size,\n",
    "                hidden_sizes,\n",
    "                input_size,\n",
    "                output_size,\n",
    "                init_w=3e-3,\n",
    "                w_scale=1,\n",
    "                b_init_value=0.1,\n",
    "                layer_norm=None,\n",
    "                batch_norm=False,\n",
    "                final_init_scale=None,\n",
    "                norm_input=False,\n",
    "                obs_norm_mean=None,\n",
    "                obs_norm_std=None,\n",
    "                width_multiplier = 1):\n",
    "        super(MimoEnsembleFlattenMLP, self).__init__()\n",
    "        self.ensemble_num = ensemble_size\n",
    "        self.hidden_activation = torch.tanh\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size*ensemble_size, hidden_sizes[0]*width_multiplier)\n",
    "        self.backbone_model = BackboneModel([layer_size*width_multiplier for layer_size in hidden_sizes],hidden_activation=self.hidden_activation)\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1]*width_multiplier, output_size* ensemble_size)\n",
    "        self.output_activation = identity\n",
    "        # initialize weights\n",
    "        init.xavier_uniform_(self.input_layer.weight)\n",
    "        self.input_layer.bias.data.fill_(0)\n",
    "        init.xavier_uniform_(self.output_layer.weight)\n",
    "        self.output_layer.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        inputs = [inputs[0], inputs[1]]\n",
    "        if self.norm_input:\n",
    "            inputs[0] = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "\n",
    "        if kwargs.get(\"sample\",None) == True:\n",
    "            inputs = inputs.repeat_interleave(self.ensemble_num,0)\n",
    "\n",
    "        return self.forward_(inputs)\n",
    "        \n",
    "    def forward_(self,input):\n",
    "        dim = len(input.shape)\n",
    "        # transform B*E to B//M*(E*M)\n",
    "        B,E,*_= input.shape\n",
    "        M = self.ensemble_num\n",
    "        h = input.view(B//M,-1) \n",
    "\n",
    "        # standard feedforward network\n",
    "        h = self.input_layer(h)\n",
    "        h = self.hidden_activation(h)\n",
    "        h = self.backbone_model(h)\n",
    "        h = self.output_layer(h)\n",
    "        output = self.output_activation(h)\n",
    "\n",
    "        # if original dim was 1D, squeeze the extra created layer\n",
    "        if  dim == 1:\n",
    "            output = output.squeeze(1)\n",
    "        return output.view(B, -1)\n",
    "\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        preds = self.forward(*inputs,sample = True)\n",
    "        B = preds.shape[0] // self.ensemble_num\n",
    "        return  torch.min(preds.view(B,self.ensemble_num,-1), dim=1)\n",
    "\n",
    "class BackboneModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, hidden_activation=F.relu):\n",
    "        super(BackboneModel, self).__init__()\n",
    "        self.hidden_activation = hidden_activation\n",
    "        for i, (in_dim, out_dim) in enumerate(zip(hidden_dim[:-1], hidden_dim[1:])):\n",
    "            self.add_module(f\"l{i}\", nn.Linear(in_dim, out_dim))\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for _, layer in self.named_children():\n",
    "            x = layer(x)\n",
    "            x = self.hidden_activation(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self,m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "A = MimoEnsembleFlattenMLP(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]),width_multiplier=2)\n",
    "\n",
    "# from flopth import flopth\n",
    "# lops, params = flopth(A, in_size=((10,),))\n",
    "# print(lops, params)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelong_rl.models.networks import ParallelizedEnsembleFlattenMLP\n",
    "from lifelong_rl.policies.base.base import MakeDeterministic\n",
    "from lifelong_rl.policies.models.tanh_gaussian_policy import TanhGaussianPolicy\n",
    "from lifelong_rl.trainers.q_learning.sac import SACTrainer\n",
    "import lifelong_rl.util.pythonplusplus as ppp\n",
    "from torch.nn import functional as F\n",
    "\n",
    "num_qs = 10 #variant['trainer_kwargs']['num_qs']\n",
    "M = 512 #variant['policy_kwargs']['layer_size']\n",
    "num_q_layers = 4 #variant['policy_kwargs']['num_q_layers']\n",
    "num_p_layers = 4 #variant['policy_kwargs']['num_p_layers']\n",
    "obs_dim = 7\n",
    "action_dim = 4\n",
    "\n",
    "# normalization\n",
    "norm_input = None#variant['norm_input']\n",
    "obs_norm_mean, obs_norm_std = None , None #variant['normalization_info']['obs_mean'], variant['normalization_info']['obs_std']\n",
    "\n",
    "qfs, target_qfs = ppp.group_init(\n",
    "    2,\n",
    "    ParallelizedEnsembleFlattenMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "policy = TanhGaussianPolicy(\n",
    "    obs_dim=obs_dim,\n",
    "    action_dim=action_dim,\n",
    "    hidden_sizes=[M] * num_p_layers,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "qfs1, target_qfs1 = ppp.group_init(\n",
    "    2,\n",
    "    BatchEnsembleFlattenMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "qfs2, target_qfs2 = ppp.group_init(\n",
    "    2,\n",
    "    MimoEnsembleFlattenMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test networks\n",
    "\n",
    "obs = torch.randn(20, obs_dim)\n",
    "acts = torch.randn(20, action_dim)\n",
    "print(qfs(obs, acts).shape)\n",
    "print(target_qfs.sample(obs, acts).shape)\n",
    "print(qfs1(obs, acts).shape)\n",
    "print(target_qfs1.sample(obs, acts)[0].shape)\n",
    "\n",
    "print(qfs2(obs, acts).shape)\n",
    "print(target_qfs2.sample(obs, acts)[0].shape)\n",
    "\n",
    "\n",
    "# def get_noised_obs(obs, actions, eps):\n",
    "#         M, N, A = obs.shape[0], obs.shape[1], actions.shape[1]\n",
    "#         size = 5\n",
    "#         obs_std = 1\n",
    "#         delta_s = 2 * eps * obs_std * (torch.rand(size, N, device=ptu.device) - 0.5)\n",
    "#         tmp_obs = obs.reshape(-1, 1, N).repeat(1, size, 1).reshape(-1, N)\n",
    "#         delta_s = delta_s.reshape(1, size, N).repeat(M, 1, 1).reshape(-1, N)\n",
    "#         noised_obs = tmp_obs + delta_s\n",
    "#         return M, A, size, noised_obs, delta_s\n",
    "\n",
    "# get_noised_obs(obs, acts, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "y = x.repeat_interleave(10, 0)  # repeat each element along dim 0 10 times\n",
    "print(y)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "y = x.repeat(10, 1)  # repeat dim 0 10 times, dim 1 1 time\n",
    "print(y)\n",
    "\n",
    "y = y.unsqueeze(0).reshape(2, 10, 3)\n",
    "print(torch.min(y, dim=0, keepdim=True).values.shape)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "A = 3\n",
    "size = 4\n",
    "print(x.repeat_interleave(size, 0))\n",
    "print(x.reshape(-1, 1, A).repeat(1, size, 1).reshape(-1, A))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a2b216ecef5dfa7933c137a5a0c108b1507eef92d12a93e0c723d41094097b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
