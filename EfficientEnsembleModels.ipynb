{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/alebeck/batchensemble-pytorch/blob/main/layers.py\n",
    "# https://github.com/quanpn90/NMTGMinor/blob/607ed45d0a3287dcbb064f012d3101300a95e891/onmt/modules/batch_ensemble/batch_ensemble_linear.py\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from lifelong_rl.torch import pytorch_util as ptu\n",
    "from lifelong_rl.torch.modules import LayerNorm\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class BatchEnsembleConv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_models, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_models = num_models\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.empty(num_models, in_channels))\n",
    "        self.gamma = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            # use one bias vector per ensemble member\n",
    "            self.bias = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X: Tensor of shape (B * M, C_in, H, W)\n",
    "        Ensemble members should be stacked in BATCH dimension.\n",
    "        Dim 0 layout:\n",
    "            ------ batch elem 0, model 0 ------\n",
    "            -------batch elem 1, model 0 ------\n",
    "                      ...\n",
    "            ------ batch elem 0, model n ------\n",
    "            -------batch elem 1, model n ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        # arguably this is the actual batch size\n",
    "        examples_per_model = batch_size // self.num_models\n",
    "\n",
    "        alpha = self.alpha.tile(1, examples_per_model).view(\n",
    "            batch_size, self.in_channels)[:, :, None, None]\n",
    "        gamma = self.gamma.tile(1, examples_per_model).view(\n",
    "            batch_size, self.out_channels)[:, :, None, None]\n",
    "\n",
    "        x = self.conv(x * alpha) * gamma\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias.tile(1, examples_per_model).view(\n",
    "                batch_size, self.out_channels)[:, :, None, None]\n",
    "            x = x + bias\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.conv.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        # random sign initialization for fast weights as mentioned in paper\n",
    "        with torch.no_grad():\n",
    "            self.alpha.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.gamma.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "\n",
    "\n",
    "class BatchEnsembleConv1D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_models, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_models = num_models\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.empty(num_models, in_channels))\n",
    "        self.gamma = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            # use one bias vector per ensemble member\n",
    "            self.bias = nn.Parameter(torch.empty(num_models, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X: Tensor of shape (B * M, C_in, W)\n",
    "        Ensemble members should be stacked in BATCH dimension.\n",
    "        Dim 0 layout:\n",
    "            ------ batch elem 0, model 0 ------\n",
    "            -------batch elem 1, model 0 ------\n",
    "                      ...\n",
    "            ------ batch elem 0, model n ------\n",
    "            -------batch elem 1, model n ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        # arguably this is the actual batch size\n",
    "        examples_per_model = batch_size // self.num_models\n",
    "\n",
    "        alpha = self.alpha.tile(1, examples_per_model).view(\n",
    "            batch_size, self.in_channels)[:, :, None]\n",
    "        gamma = self.gamma.tile(1, examples_per_model).view(\n",
    "            batch_size, self.out_channels)[:, :, None]\n",
    "\n",
    "        x = self.conv(x * alpha) * gamma\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias.tile(1, examples_per_model).view(\n",
    "                batch_size, self.out_channels)[:, :, None]\n",
    "            x = x + bias\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.conv.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        # random sign initialization for fast weights as mentioned in paper\n",
    "        with torch.no_grad():\n",
    "            self.alpha.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.gamma.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "\n",
    "\n",
    "class BatchEnsembleLinearPlus(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, ensemble_size, bias=True, diversity = False):\n",
    "        super().__init__()\n",
    "        self.in_features = input_size\n",
    "        self.out_features = output_size\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.weight_diversity = diversity\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(output_size, input_size))  # m*n\n",
    "        self.r = nn.Parameter(torch.empty(ensemble_size, input_size))  # M*m\n",
    "        self.s = nn.Parameter(torch.empty(ensemble_size, output_size))  # M*n\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(ensemble_size, output_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Expects input in shape (B*M, C_in), dim 0 layout:\n",
    "            ------ x0, model 0 ------\n",
    "            -------x0, model 1 ------\n",
    "                      ...\n",
    "            ------ x1, model 0 ------\n",
    "            -------x1, model 1 ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        B = X.shape[0] // self.ensemble_size\n",
    "        X = X.view(B, self.ensemble_size, -1)  # Reshape input to (B, M, C_in)\n",
    "        R = self.r.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        S = self.s.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        bias = self.bias.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "\n",
    "        # Eq. 5 from BatchEnsembles paper\n",
    "        output = torch.matmul((X * R), self.W.t()) * S + bias  # (B, M, C_out)\n",
    "        \n",
    "        # Flatten output back to (B*M, C_out)\n",
    "        output = output.view(B * self.ensemble_size, -1)\n",
    "        diver =  torch.tensor(0) \n",
    "        if self.weight_diversity:\n",
    "          R1 = self.r/torch.norm(self.r,dim=1,keepdim=True)\n",
    "          S1 = self.s/torch.norm(self.s,dim=1,keepdim=True)\n",
    "          diver = 1 - (torch.mean(torch.matmul(R1,R1.t()) + torch.matmul(S1,S1.t())))/2\n",
    "\n",
    "        return output,diver\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
    "        nn.init.xavier_uniform_(self.W,gain=nn.init.calculate_gain('relu'))\n",
    "        # Another way to initialize the fast weights\n",
    "        #nn.init.normal_(self.r, mean=1., std=0.1)\n",
    "        #nn.init.normal_(self.s, mean=1., std=0.1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "        if True:\n",
    "            with torch.no_grad():\n",
    "              # random sign initialization from paper\n",
    "                self.r.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "                self.s.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "        else:\n",
    "            # nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            # nn.init.normal_(self.s, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BatchEnsembleLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, ensemble_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = input_size\n",
    "        self.out_features = output_size\n",
    "        self.ensemble_size = ensemble_size\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(output_size, input_size))  # m*n\n",
    "        self.r = nn.Parameter(torch.empty(ensemble_size, input_size))  # M*m\n",
    "        self.s = nn.Parameter(torch.empty(ensemble_size, output_size))  # M*n\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(ensemble_size, output_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Expects input in shape (B*M, C_in), dim 0 layout:\n",
    "            ------ x0, model 0 ------\n",
    "            -------x0, model 1 ------\n",
    "                      ...\n",
    "            ------ x1, model 0 ------\n",
    "            -------x1, model 1 ------\n",
    "                      ...\n",
    "        \"\"\"\n",
    "        B = X.shape[0] // self.ensemble_size\n",
    "        X = X.view(B, self.ensemble_size, -1)  # Reshape input to (B, M, C_in)\n",
    "        R = self.r.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        S = self.s.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        bias = self.bias.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "\n",
    "        # Eq. 5 from BatchEnsembles paper\n",
    "        output = torch.matmul((X * R), self.W.t()) * S + bias  # (B, M, C_out)\n",
    "        \n",
    "        # Flatten output back to (B*M, C_out)\n",
    "        output = output.view(B * self.ensemble_size, -1)\n",
    "        return output\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
    "        nn.init.xavier_uniform_(self.W,gain=nn.init.calculate_gain('relu'))\n",
    "        # Another way to initialize the fast weights\n",
    "        #nn.init.normal_(self.r, mean=1., std=0.1)\n",
    "        #nn.init.normal_(self.s, mean=1., std=0.1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "        if True:\n",
    "            with torch.no_grad():\n",
    "              # random sign initialization from paper\n",
    "                self.r.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "                self.s.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "        else:\n",
    "            # nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            # nn.init.normal_(self.s, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchEnsembleFlattenMLP(\n",
      "  (fc0): BatchEnsembleLinear()\n",
      "  (fc1): BatchEnsembleLinear()\n",
      "  (last_fc): BatchEnsembleLinear()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BatchEnsembleFlattenMLP(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ensemble_size,\n",
    "            hidden_sizes,\n",
    "            input_size,\n",
    "            output_size,\n",
    "            init_w=3e-3,\n",
    "            hidden_init=ptu.fanin_init,\n",
    "            w_scale=1,\n",
    "            b_init_value=0.1,\n",
    "            layer_norm=None,\n",
    "            batch_norm=False,\n",
    "            final_init_scale=None,\n",
    "            norm_input=False,\n",
    "            obs_norm_mean=None,\n",
    "            obs_norm_std=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.sampler = np.random.default_rng()\n",
    "\n",
    "        self.hidden_activation = F.relu\n",
    "        self.output_activation = identity\n",
    "        \n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "\n",
    "        self.fcs = []\n",
    "\n",
    "        if batch_norm:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        in_size = input_size\n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = BatchEnsembleLinear(\n",
    "                ensemble_size=ensemble_size,\n",
    "                input_size=in_size,\n",
    "                output_size=next_size,\n",
    "            )\n",
    "            self.__setattr__('fc%d'% i, fc)\n",
    "            self.fcs.append(fc)\n",
    "            in_size = next_size\n",
    "\n",
    "        self.last_fc = BatchEnsembleLinear(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "        )\n",
    "        if final_init_scale is None:\n",
    "            self.last_fc.W.data.uniform_(-init_w, init_w)\n",
    "            self.last_fc.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        \"\"\"Calculate the forward pass of Q(s, a).\n",
    "\n",
    "        Args:\n",
    "            inputs: list[observation,action]: list of tensors containing the observation and action size B x obs_dim , B x act_dim \n",
    "\n",
    "        Returns:\n",
    "            Q(s,a): return Q(s,a) size B x 1, where emsamble members output are stack along dim 0 [q_m0 , q_m1, ...,q_mN, q_m0, q_m1, ...]^T \n",
    "        \"\"\"\n",
    "        \n",
    "        inputs = [inputs[0], inputs[1]]\n",
    "        if self.norm_input:\n",
    "            inputs[0] = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "\n",
    "        flat_inputs = torch.cat(inputs, dim=-1)\n",
    "        dim=len(flat_inputs.shape)\n",
    "        if kwargs.get(\"sample\",False):\n",
    "            flat_inputs = flat_inputs.repeat_interleave(self.ensemble_size,0)\n",
    "\n",
    "        # input normalization\n",
    "        h = flat_inputs\n",
    "\n",
    "        # standard feedforward network\n",
    "        for _, fc in enumerate(self.fcs):\n",
    "            h = fc(h)\n",
    "            h = self.hidden_activation(h)\n",
    "            if hasattr(self, 'layer_norm') and (self.layer_norm is not None):\n",
    "                h = self.layer_norm(h)\n",
    "        preactivation = self.last_fc(h)\n",
    "        output = self.output_activation(preactivation)\n",
    "        return output\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        preds = self.forward(*inputs,sample=True)\n",
    "        B = preds.shape[0] // self.ensemble_size\n",
    "        #(B*Self.ensemble_size,1) => (self.ensemble_size, B, 1)\n",
    "        preds = preds.view(B,self.ensemble_size,-1 )\n",
    "        # Return min, mean and std of the ensemble\n",
    "        return torch.min(preds, dim=1)[0],preds.mean(dim=1), preds.std(dim=1)\n",
    " \n",
    "\n",
    "\n",
    "    def fit_input_stats(self, data, mask=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "A = BatchEnsembleFlattenMLP(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]))\n",
    "print(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Ensemble Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchEnsembleFlattenMLPPlus(\n",
      "  (fc0): BatchEnsembleLinearPlus()\n",
      "  (fc1): BatchEnsembleLinearPlus()\n",
      "  (last_fc): BatchEnsembleLinearPlus()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Improve efficiency\n",
    "\n",
    "\n",
    "\n",
    "class BatchEnsembleFlattenMLPPlus(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ensemble_size,\n",
    "            hidden_sizes,\n",
    "            input_size,\n",
    "            output_size,\n",
    "            init_w=3e-3,\n",
    "            hidden_init=ptu.fanin_init,\n",
    "            w_scale=1,\n",
    "            b_init_value=0.1,\n",
    "            layer_norm=None,\n",
    "            batch_norm=False,\n",
    "            final_init_scale=None,\n",
    "            norm_input=False,\n",
    "            obs_norm_mean=None,\n",
    "            obs_norm_std=None,\n",
    "            hidden_activate=F.gelu, # THANH\n",
    "            diversity_regularize = False # THANH\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.ensemble_num = ensemble_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.sampler = np.random.default_rng()\n",
    "\n",
    "        self.hidden_activation = hidden_activate\n",
    "        self.output_activation = identity\n",
    "        \n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "\n",
    "        self.fcs = []\n",
    "        self.diversity_regularize= diversity_regularize\n",
    "\n",
    "        if batch_norm:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        in_size = input_size\n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = BatchEnsembleLinearPlus(\n",
    "                ensemble_size=ensemble_size,\n",
    "                input_size=in_size,\n",
    "                output_size=next_size,\n",
    "                diversity = self.diversity_regularize,\n",
    "            )\n",
    "            self.__setattr__('fc%d'% i, fc)\n",
    "            self.fcs.append(fc)\n",
    "            in_size = next_size\n",
    "\n",
    "        self.last_fc = BatchEnsembleLinearPlus(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "            diversity = self.diversity_regularize,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        if self.norm_input:\n",
    "            obs = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "            flat_inputs = torch.cat([obs, inputs[1]], dim=-1)\n",
    "        else:\n",
    "            flat_inputs = torch.cat([inputs[0], inputs[1]], dim=-1)\n",
    "        \n",
    "        if kwargs.get(\"sample\", False):\n",
    "            flat_inputs = flat_inputs.repeat_interleave(self.ensemble_size, 0)\n",
    "\n",
    "        # input normalization\n",
    "        h = flat_inputs\n",
    "\n",
    "        # standard feedforward network\n",
    "        diversity = 0\n",
    "        for _, fc in enumerate(self.fcs):\n",
    "            h,div = fc(h)\n",
    "            diversity +=div \n",
    "            h = self.hidden_activation(h)\n",
    "            if hasattr(self, 'layer_norm') and (self.layer_norm is not None):\n",
    "                h = self.layer_norm(h)\n",
    "        preactivation,div = self.last_fc(h)\n",
    "        diversity +=div\n",
    "        output = self.output_activation(preactivation)\n",
    "        return output,diversity\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        preds,*_ = self.forward(*inputs,sample=True)\n",
    "        B = preds.shape[0] // self.ensemble_size\n",
    "        #(B*Self.ensemble_size,1) => (self.ensemble_size, B, 1)\n",
    "        preds = preds.view(B, self.ensemble_size, -1)\n",
    "        # Return min, mean and std of the ensemble\n",
    "        return torch.min(preds, dim=1)[0],0#,preds.mean(dim=1), preds.std(dim=1)\n",
    "    \n",
    "    def fit_input_stats(self, data, mask=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "A = BatchEnsembleFlattenMLPPlus(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(10)\n",
    "print(a.shape)\n",
    "a.unsqueeze(1)\n",
    "print(a.shape)\n",
    "a.view(-1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank-1 Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchEnsembleFlattenMLPPlus(\n",
      "  (fc0): BatchEnsembleLinearPlus()\n",
      "  (fc1): BatchEnsembleLinearPlus()\n",
      "  (last_fc): BatchEnsembleLinearPlus()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BatchEnsembleLinearRank1(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, ensemble_size, bias=True, diversity = False):\n",
    "        super().__init__()\n",
    "        self.in_features = input_size\n",
    "        self.out_features = output_size\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.weight_diversity = diversity\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(output_size, input_size))  # m*n\n",
    "        self.r = nn.Parameter(torch.empty(ensemble_size, input_size))  # M*m\n",
    "        self.s = nn.Parameter(torch.empty(ensemble_size, output_size))  # M*n\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(ensemble_size, output_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X: (B, M, C_in)\n",
    "        return (B, M, C_out)\n",
    "\n",
    "        '''\n",
    "        R = self.r.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        S = self.s.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        bias = self.bias.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "\n",
    "        # Eq. 5 from BatchEnsembles paper\n",
    "        output = torch.matmul((X * R), self.W.t()) * S + bias  # (B, M, C_out)\n",
    "\n",
    "        diver =  torch.tensor(0) \n",
    "        if self.weight_diversity:\n",
    "          R1 = self.r/torch.norm(self.r,dim=1,keepdim=True)\n",
    "          S1 = self.s/torch.norm(self.s,dim=1,keepdim=True)\n",
    "          diver = 1 - (torch.mean(torch.matmul(R1,R1.t()) + torch.matmul(S1,S1.t())))/2\n",
    "\n",
    "        return output,diver\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
    "        nn.init.xavier_uniform_(self.W,gain=nn.init.calculate_gain('relu'))\n",
    "        # Another way to initialize the fast weights\n",
    "        #nn.init.normal_(self.r, mean=1., std=0.1)\n",
    "        #nn.init.normal_(self.s, mean=1., std=0.1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "        if True:\n",
    "            with torch.no_grad():\n",
    "              # random sign initialization from paper\n",
    "                self.r.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "                self.s.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "        else:\n",
    "            # nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            # nn.init.normal_(self.s, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "            nn.init.normal_(self.r, mean=1., std=0.5)\n",
    "\n",
    "\n",
    "class BatchEnsembleFlattenRank1(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ensemble_size,\n",
    "            hidden_sizes,\n",
    "            input_size,\n",
    "            output_size,\n",
    "            layer_norm=None,\n",
    "            batch_norm=False,\n",
    "            norm_input=False,\n",
    "            obs_norm_mean=None,\n",
    "            obs_norm_std=None,\n",
    "            hidden_activate=F.gelu, # THANH\n",
    "            diversity_regularize = False # THANH\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.ensemble_num = ensemble_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.sampler = np.random.default_rng()\n",
    "\n",
    "        self.hidden_activation = hidden_activate\n",
    "        self.output_activation = identity\n",
    "        \n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "\n",
    "        self.fcs = []\n",
    "        self.diversity_regularize= diversity_regularize\n",
    "\n",
    "        if batch_norm:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        in_size = input_size\n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = BatchEnsembleLinearRank1(\n",
    "                ensemble_size=ensemble_size,\n",
    "                input_size=in_size,\n",
    "                output_size=next_size,\n",
    "                diversity = self.diversity_regularize,\n",
    "            )\n",
    "            self.__setattr__('fc%d'% i, fc)\n",
    "            self.fcs.append(fc)\n",
    "            in_size = next_size\n",
    "\n",
    "        self.last_fc = BatchEnsembleLinearRank1(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "            diversity = self.diversity_regularize,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        if self.norm_input:\n",
    "            obs = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "            flat_inputs = torch.cat([obs, inputs[1]], dim=-1)\n",
    "        else:\n",
    "            flat_inputs = torch.cat([inputs[0], inputs[1]], dim=-1)\n",
    "\n",
    "        flat_inputs = flat_inputs.repeat_interleave(self.ensemble_size, 0).view(-1,self.ensemble_size, self.input_size)\n",
    "\n",
    "        # input normalization\n",
    "        h = flat_inputs\n",
    "\n",
    "        # standard feedforward network\n",
    "        diversity = 0\n",
    "        for _, fc in enumerate(self.fcs):\n",
    "            h,div = fc(h)\n",
    "            diversity +=div \n",
    "            h = self.hidden_activation(h)\n",
    "            if hasattr(self, 'layer_norm') and (self.layer_norm is not None):\n",
    "                h = self.layer_norm(h)\n",
    "        preactivation,div = self.last_fc(h)\n",
    "        diversity +=div\n",
    "        output = self.output_activation(preactivation) # (B,M, C_out)\n",
    "        # Transpose to (M, B, C_out)\n",
    "        output = output.transpose(0, 1).contiguous()\n",
    "        \n",
    "        return output #,diversity\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        preds = self.forward(*inputs)\n",
    "        return torch.min(preds, dim=0)[0]\n",
    "    \n",
    "    def fit_input_stats(self, data, mask=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "A = BatchEnsembleFlattenMLPPlus(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]))\n",
    "print(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAUSS ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchEnsembleLinearGauss(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, ensemble_size, bias=True, diversity = False):\n",
    "        super().__init__()\n",
    "        self.in_features = input_size\n",
    "        self.out_features = output_size\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.weight_diversity = diversity\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(output_size, input_size))  # m*n\n",
    "        self.r = nn.Parameter(torch.empty(ensemble_size, input_size))  # M*m\n",
    "        self.s = nn.Parameter(torch.empty(ensemble_size, output_size))  # M*n\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(ensemble_size, output_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X: (B, M, C_in)\n",
    "        return (B, M, C_out)\n",
    "\n",
    "        '''\n",
    "        R = self.r.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        S = self.s.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "        bias = self.bias.unsqueeze(0)  # Add a dimension for broadcasting\n",
    "\n",
    "        # Eq. 5 from BatchEnsembles paper\n",
    "        output = torch.matmul((X * R), self.W.t()) * S + bias  # (B, M, C_out)\n",
    "\n",
    "        diver =  torch.tensor(0) \n",
    "        if self.weight_diversity:\n",
    "          R1 = self.r/torch.norm(self.r,dim=1,keepdim=True)\n",
    "          S1 = self.s/torch.norm(self.s,dim=1,keepdim=True)\n",
    "          diver = 1 - (torch.mean(torch.matmul(R1,R1.t()) + torch.matmul(S1,S1.t())))/2\n",
    "\n",
    "        return output,diver\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # random sign initialization from paper\n",
    "            self.r.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "            self.s.bernoulli_(0.5).mul_(2).add_(-1)\n",
    "\n",
    "\n",
    "\n",
    "class BatchEnsembleGaussMLP(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            ensemble_size,\n",
    "            hidden_sizes,\n",
    "            input_size,\n",
    "            output_size,\n",
    "            init_w=3e-3,\n",
    "            layer_norm=None,\n",
    "            batch_norm=False,\n",
    "            final_init_scale=None,\n",
    "            norm_input=False,\n",
    "            obs_norm_mean=None,\n",
    "            obs_norm_std=None,\n",
    "            hidden_activate=F.gelu, # THANH\n",
    "            diversity_regularize = False # THANH\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.ensemble_num = ensemble_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.sampler = np.random.default_rng()\n",
    "\n",
    "        self.hidden_activation = hidden_activate\n",
    "        self.output_activation = identity\n",
    "        \n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "\n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        self.norm_input = norm_input\n",
    "\n",
    "        self.fcs = []\n",
    "        self.diversity_regularize= diversity_regularize\n",
    "\n",
    "        if batch_norm:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        in_size = input_size\n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = BatchEnsembleLinearGauss(\n",
    "                ensemble_size=ensemble_size,\n",
    "                input_size=in_size,\n",
    "                output_size=next_size,\n",
    "                diversity = self.diversity_regularize,\n",
    "            )\n",
    "            self.__setattr__('fc%d'% i, fc)\n",
    "            self.fcs.append(fc)\n",
    "            in_size = next_size\n",
    "\n",
    "        self.mu = BatchEnsembleLinearGauss(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "            diversity = self.diversity_regularize,\n",
    "        )\n",
    "\n",
    "        self.var = BatchEnsembleLinearGauss(\n",
    "            ensemble_size=ensemble_size,\n",
    "            input_size=in_size,\n",
    "            output_size=output_size,\n",
    "            diversity = self.diversity_regularize,\n",
    "        )\n",
    "        if final_init_scale is None:\n",
    "            self.mu.W.data.uniform_(-init_w, init_w)\n",
    "            self.var.W.data.uniform_(-init_w, init_w)\n",
    "            self.mu.bias.data.uniform_(-init_w, init_w)\n",
    "            self.var.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "\n",
    "        if self.norm_input:\n",
    "            obs = (inputs[0] - self.obs_norm_mean) / self.obs_norm_std\n",
    "            flat_inputs = torch.cat([obs, inputs[1]], dim=-1)\n",
    "        else:\n",
    "            flat_inputs = torch.cat([inputs[0], inputs[1]], dim=-1)\n",
    "\n",
    "        flat_inputs = flat_inputs.repeat_interleave(self.ensemble_size, 0).view(-1,self.ensemble_size, self.input_size)\n",
    "\n",
    "        # input normalization\n",
    "        h = flat_inputs\n",
    "\n",
    "        # standard feedforward network\n",
    "        diversity = 0\n",
    "        for _, fc in enumerate(self.fcs):\n",
    "            h,div = fc(h)\n",
    "            diversity +=div \n",
    "            h = self.hidden_activation(h)\n",
    "            if hasattr(self, 'layer_norm') and (self.layer_norm is not None):\n",
    "                h = self.layer_norm(h)\n",
    "        mu_pre,div = self.mu(h)\n",
    "        diversity +=div\n",
    "        var_pre,div = self.var(h)\n",
    "        diversity +=div\n",
    "        var = torch.exp(var_pre)\n",
    "        var = var.transpose(0, 1).contiguous()\n",
    "        mu = self.output_activation(mu_pre)\n",
    "        mu = mu.transpose(0, 1).contiguous()\n",
    "        return mu,var, diversity\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "\n",
    "        preds,vars,*_ = self.forward(*inputs)\n",
    "        return preds,vars\n",
    "    \n",
    "    def fit_input_stats(self, data, mask=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MimoEnsembleFlattenMLP(\n",
      "  (input_layer): Linear(in_features=40, out_features=128, bias=True)\n",
      "  (backbone_model): BackboneModel(\n",
      "    (l0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/noowad93/MIMO-pytorch\n",
    "# (The link above may contain some errors)\n",
    "# https://colab.research.google.com/drive/16i8Wd8hYYgZfVLs6MPVFZ2faccpnYkyk?usp=sharing#scrollTo=i_2GT74Ecu0c\n",
    "# https://colab.research.google.com/drive/1JIgyVeEmlOH-j0oGmeDLV8iE5UYdreYm#scrollTo=Ac1oS_S8kQOB\n",
    "\n",
    "class MimoEnsembleFlattenMLP(nn.Module):\n",
    "    def __init__(self, \n",
    "                ensemble_size,\n",
    "                hidden_sizes,\n",
    "                input_size,\n",
    "                output_size,\n",
    "                init_w=3e-3,\n",
    "                w_scale=1,\n",
    "                b_init_value=0.1,\n",
    "                layer_norm=None,\n",
    "                batch_norm=False,\n",
    "                final_init_scale=None,\n",
    "                norm_input=False,\n",
    "                obs_norm_mean=None,\n",
    "                obs_norm_std=None,\n",
    "                width_multiplier = 1):\n",
    "        super(MimoEnsembleFlattenMLP, self).__init__()\n",
    "        self.ensemble_num = ensemble_size\n",
    "        self.hidden_activation = torch.tanh\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size*ensemble_size, hidden_sizes[0]*width_multiplier)\n",
    "        self.backbone_model = BackboneModel([layer_size*width_multiplier for layer_size in hidden_sizes],hidden_activation=self.hidden_activation)\n",
    "        self.norm_input = norm_input\n",
    "        if self.norm_input:\n",
    "            self.obs_norm_mean, self.obs_norm_std = ptu.from_numpy(obs_norm_mean), ptu.from_numpy(obs_norm_std + 1e-6)\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1]*width_multiplier, output_size* ensemble_size)\n",
    "        self.output_activation = identity\n",
    "        # initialize weights\n",
    "        init.xavier_uniform_(self.input_layer.weight)\n",
    "        self.input_layer.bias.data.fill_(0)\n",
    "        init.xavier_uniform_(self.output_layer.weight)\n",
    "        self.output_layer.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        inputs = [inputs[0], inputs[1]]\n",
    "        if self.norm_input:\n",
    "            inputs[0].sub_(self.obs_norm_mean).div_(self.obs_norm_std)\n",
    "\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "\n",
    "        if kwargs.get(\"sample\",None) == True:\n",
    "            inputs = inputs.repeat_interleave(self.ensemble_num,0)\n",
    "\n",
    "        return self.forward_(inputs)\n",
    "        \n",
    "    def forward_(self,input):\n",
    "        dim = len(input.shape)\n",
    "        # transform B*E to B//M*(E*M)\n",
    "        B,E,*_= input.shape\n",
    "        M = self.ensemble_num\n",
    "        h = input.view(B//M,-1) \n",
    "\n",
    "        # standard feedforward network\n",
    "        h = self.input_layer(h)\n",
    "        h = self.hidden_activation(h)\n",
    "        h = self.backbone_model(h)\n",
    "        h = self.output_layer(h)\n",
    "        output = self.output_activation(h)\n",
    "\n",
    "        # if original dim was 1D, squeeze the extra created layer\n",
    "        if  dim == 1:\n",
    "            output = output.squeeze(1)\n",
    "        return output.view(B, -1)\n",
    "\n",
    "\n",
    "    def sample(self, *inputs):\n",
    "        preds = self.forward(*inputs,sample = True)\n",
    "        B = preds.shape[0] // self.ensemble_num\n",
    "        return  torch.min(preds.view(B,self.ensemble_num,-1), dim=1)\n",
    "\n",
    "class BackboneModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, hidden_activation=F.relu):\n",
    "        super(BackboneModel, self).__init__()\n",
    "        self.hidden_activation = hidden_activation\n",
    "        for i, (in_dim, out_dim) in enumerate(zip(hidden_dim[:-1], hidden_dim[1:])):\n",
    "            self.add_module(f\"l{i}\", nn.Linear(in_dim, out_dim))\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for _, layer in self.named_children():\n",
    "            x = layer(x)\n",
    "            x = self.hidden_activation(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self,m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "A = MimoEnsembleFlattenMLP(ensemble_size=10, hidden_sizes=[64,64], input_size=4, output_size=1, norm_input=True, obs_norm_mean=np.array([0,0]), obs_norm_std=np.array([1,1]),width_multiplier=2)\n",
    "\n",
    "# from flopth import flopth\n",
    "# lops, params = flopth(A, in_size=((10,),))\n",
    "# print(lops, params)\n",
    "print(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelong_rl.models.networks import ParallelizedEnsembleFlattenMLP\n",
    "from lifelong_rl.policies.base.base import MakeDeterministic\n",
    "from lifelong_rl.policies.models.tanh_gaussian_policy import TanhGaussianPolicy\n",
    "from lifelong_rl.trainers.q_learning.sac import SACTrainer\n",
    "import lifelong_rl.util.pythonplusplus as ppp\n",
    "from torch.nn import functional as F\n",
    "\n",
    "num_qs = 20 #variant['trainer_kwargs']['num_qs']\n",
    "M = 512 #variant['policy_kwargs']['layer_size']\n",
    "num_q_layers = 4 #variant['policy_kwargs']['num_q_layers']\n",
    "num_p_layers = 4 #variant['policy_kwargs']['num_p_layers']\n",
    "obs_dim = 7\n",
    "action_dim = 4\n",
    "\n",
    "# normalization\n",
    "norm_input = False#variant['norm_input']\n",
    "obs_norm_mean, obs_norm_std = torch.randn(obs_dim).numpy() , torch.randn(obs_dim).numpy() #variant['normalization_info']['obs_mean'], variant['normalization_info']['obs_std']\n",
    "\n",
    "qfs, target_qfs = ppp.group_init(\n",
    "    2,\n",
    "    ParallelizedEnsembleFlattenMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "qfs3, target_qfs3 = ppp.group_init(\n",
    "    2,\n",
    "    BatchEnsembleFlattenRank1,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "qfs4, target_qfs4 = ppp.group_init(\n",
    "    2,\n",
    "    BatchEnsembleGaussMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "policy = TanhGaussianPolicy(\n",
    "    obs_dim=obs_dim,\n",
    "    action_dim=action_dim,\n",
    "    hidden_sizes=[M] * num_p_layers,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "qfs1, target_qfs1 = ppp.group_init(\n",
    "    2,\n",
    "    BatchEnsembleFlattenMLPPlus,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n",
    "qfs2, target_qfs2 = ppp.group_init(\n",
    "    2,\n",
    "    MimoEnsembleFlattenMLP,\n",
    "    ensemble_size=num_qs,\n",
    "    hidden_sizes=[M] * num_q_layers,\n",
    "    input_size=obs_dim + action_dim,\n",
    "    output_size=1,\n",
    "    layer_norm=None,\n",
    "    norm_input=norm_input,\n",
    "    obs_norm_mean=obs_norm_mean,\n",
    "    obs_norm_std=obs_norm_std,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 500, 1])\n",
      "torch.Size([500, 1])\n",
      "torch.Size([20, 500, 1])\n",
      "torch.Size([500, 1])\n",
      "torch.Size([500, 20, 1])\n",
      "torch.Size([500, 20, 1])\n",
      "torch.Size([500, 1])\n",
      "torch.Size([500, 1])\n",
      "torch.Size([500, 1])\n",
      "torch.Size([500, 1])\n",
      "\n",
      "\n",
      "---Begin Timer Report (root)---\n",
      "Timer Name:          root (running)\n",
      "Total Time (s):      7.65\n",
      "Stamps Sum:          7.642\n",
      "Self Time (Agg.):    0.0002102\n",
      "\n",
      "\n",
      "Intervals\n",
      "---------\n",
      "start .............. 5.657e-05\n",
      "EnsembleFlattenMLP . 1.723\n",
      "EnsembleFlattenRank1  2.249\n",
      "EnsembleGaussMLP ... 2.315\n",
      "BatchEnsembleFlattenMLP  1.271\n",
      "MimoEnsembleFlattenMLP  0.0829\n",
      "\n",
      "---End Timer Report (root)---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test networks\n",
    "import gtimer as gt\n",
    "obs = torch.randn(500, obs_dim)\n",
    "acts = torch.randn(500, action_dim)\n",
    "\n",
    "print(qfs(obs, acts).shape)\n",
    "print(target_qfs.sample(obs, acts).shape)\n",
    "\n",
    "print(qfs3(obs, acts).shape)\n",
    "print(target_qfs3.sample(obs, acts).shape)\n",
    "\n",
    "print(qfs4(obs, acts)[0].shape)\n",
    "print(target_qfs4.sample(obs, acts)[0].shape)\n",
    "\n",
    "\n",
    "print(qfs1(obs, acts)[0].shape) if isinstance(qfs1(obs, acts),tuple) else print(qfs1(obs, acts).shape)\n",
    "print(target_qfs1.sample(obs, acts)[0].shape)\n",
    "\n",
    "print(qfs2(obs, acts).shape)\n",
    "print(target_qfs2.sample(obs, acts)[0].shape)\n",
    "\n",
    "gt.reset()\n",
    "gt.start()\n",
    "gt.stamp('start')\n",
    "for i in range(10):\n",
    "    qfs(obs, acts)\n",
    "    target_qfs.sample(obs, acts)\n",
    "gt.stamp('EnsembleFlattenMLP')\n",
    "\n",
    "for i in range(10):\n",
    "    qfs3(obs, acts)\n",
    "    target_qfs3.sample(obs, acts)\n",
    "gt.stamp('EnsembleFlattenRank1')\n",
    "\n",
    "for i in range(10):\n",
    "    qfs4(obs, acts)\n",
    "    target_qfs4.sample(obs, acts)\n",
    "gt.stamp('EnsembleGaussMLP')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    qfs1(obs, acts)\n",
    "    target_qfs1.sample(obs, acts)\n",
    "gt.stamp('BatchEnsembleFlattenMLP')\n",
    "for i in range(10):\n",
    "    qfs2(obs, acts)\n",
    "    target_qfs2.sample(obs, acts)\n",
    "gt.stamp('MimoEnsembleFlattenMLP')\n",
    "\n",
    "print(gt.report())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "y = x.repeat_interleave(10, 0)  # repeat each element along dim 0 10 times\n",
    "print(y)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "y = x.repeat(10, 1)  # repeat dim 0 10 times, dim 1 1 time\n",
    "print(y)\n",
    "\n",
    "y = y.unsqueeze(0).reshape(2, 10, 3)\n",
    "print(torch.min(y, dim=0, keepdim=True).values.shape)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "A = 3\n",
    "size = 4\n",
    "print(x.repeat_interleave(size, 0))\n",
    "print(x.reshape(-1, 1, A).repeat(1, size, 1).reshape(-1, A))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a2b216ecef5dfa7933c137a5a0c108b1507eef92d12a93e0c723d41094097b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
